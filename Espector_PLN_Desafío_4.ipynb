{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nataliaespector/CEIA_TPs_Procesamiento_Lenguaje_Natural_1/blob/main/Espector_PLN_Desaf%C3%ADo_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Traductor\n",
        "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objeto es utilizar datos disponibles de Anki de traducciones de texto en diferentes idiomas. Se construirá un modelo traductor seq2seq utilizando encoder-decoder.\\\n",
        "[LINK](https://www.manythings.org/anki/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgYatMIdk_eT",
        "outputId": "ad3bb00c-0eac-478d-ccb7-fdcdf53d66b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchsummar actualmente tiene un problema con las LSTM, por eso\n",
        "# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n",
        "!pip3 install torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYpIWGaXxfKe",
        "outputId": "9e1c0aba-8600-4d34-9795-f0ab0ba69ae8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ],
      "metadata": {
        "id": "GHFPS5KNxgR9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - Datos"
      ],
      "metadata": {
        "id": "5BFiCH8nxoIY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb54494-1ffa-42ba-c14d-59acf5e49d9b"
      },
      "source": [
        "# Descargar la carpeta de dataset\n",
        "\n",
        "import os\n",
        "if os.access('spa-eng', os.F_OK) is False:\n",
        "    if os.access('spa-eng.zip', os.F_OK) is False:\n",
        "        !curl -L -o 'spa-eng.zip' 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "    !unzip -q spa-eng.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9aNLZBDtA5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7d9d89-7d86-48e1-8365-cf405da4a771"
      },
      "source": [
        "# dataset_file\n",
        "\n",
        "text_file = \"./spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "# Por limitaciones de RAM no se leen todas las filas\n",
        "MAX_NUM_SENTENCES = 60000\n",
        "\n",
        "# Mezclar el dataset, forzar semilla siempre igual\n",
        "np.random.seed([40])\n",
        "np.random.shuffle(lines)\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "count = 0\n",
        "\n",
        "for line in lines:\n",
        "    count += 1\n",
        "    if count > MAX_NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "    if '\\t' not in line:\n",
        "        continue\n",
        "\n",
        "    # Input sentence --> eng\n",
        "    # output --> spa\n",
        "    input_sentence, output = line.rstrip().split('\\t')\n",
        "\n",
        "    # output sentence (decoder_output) tiene <eos>\n",
        "    output_sentence = output + ' <eos>'\n",
        "    # output sentence input (decoder_input) tiene <sos>\n",
        "    output_sentence_input = '<sos> ' + output\n",
        "\n",
        "    input_sentences.append(input_sentence)\n",
        "    output_sentences.append(output_sentence)\n",
        "    output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows disponibles:\", len(lines))\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows disponibles: 118964\n",
            "Cantidad de rows utilizadas: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93IGMKFb73q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f617a0e3-b4f4-4689-8662-019f85001b49"
      },
      "source": [
        "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('A deal is a deal.',\n",
              " 'Un trato es un trato. <eos>',\n",
              " '<sos> Un trato es un trato.')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WAZGOTfGyha"
      },
      "source": [
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 15000"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF1W6peoFGXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720f041a-af32-4824-e249-8ed5553e4369"
      },
      "source": [
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una máxima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "\n",
        "# tokenizador de inglés\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada más larga:\", max_input_len)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 10692\n",
            "Sentencia de entrada más larga: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBzdKiTVIBYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932488a9-e62f-4949-df2e-b3c59e2f570b"
      },
      "source": [
        "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
        "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "# tokenizador de español\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida más larga:\", max_out_len)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 19614\n",
            "Sentencia de salida más larga: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqb8ZJ4sJHgv"
      },
      "source": [
        "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgLC706EQx3p"
      },
      "source": [
        "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
        "# a la mitad:\n",
        "max_input_len = 47\n",
        "max_out_len = 50"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOn9N57IuYz"
      },
      "source": [
        "A la hora de realizar padding es importante tener en cuenta que en el encoder los ceros se agregan al comienzo y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ob4hAWJkcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6298a5c0-2a72-47d8-bc61-727e16823898"
      },
      "source": [
        "#from torch_helpers import pad_sequences\n",
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows del dataset: 60000\n",
            "encoder_input_sequences shape: (60000, 47)\n",
            "decoder_input_sequences shape: (60000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VySR1pzx9UG",
        "outputId": "dd55f9e2-4ac2-46e9-9c87-48cc094355f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_output_sequences shape: (60000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(decoder_output_sequences).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANTOqJ0WWw-q",
        "outputId": "f55a32ae-6ddf-458b-9d39-4ab355c2a9ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, decoder_output, pad_idx=0):\n",
        "        # Entradas como índices (Long)\n",
        "        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int64))  # [N, Tenc]\n",
        "        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int64))  # [N, Tdec]\n",
        "\n",
        "        # 🔧 SALIDA COMO ÍNDICES (¡sin one-hot!)\n",
        "        # decoder_output ya viene como índices [N, Tdec]\n",
        "        self.decoder_outputs = torch.from_numpy(decoder_output.astype(np.int64))  # [N, Tdec]\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "        self.len = self.decoder_outputs.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Devolvemos todo como Long (índices)\n",
        "        return (\n",
        "            self.encoder_inputs[index].long(),\n",
        "            self.decoder_inputs[index].long(),\n",
        "            self.decoder_outputs[index].long()\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "SD0bpM32yWfB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = Data(\n",
        "    encoder_input_sequences,     # [N, Tenc] índices\n",
        "    decoder_input_sequences,     # [N, Tdec] índices (con <sos> al principio)\n",
        "    decoder_output_sequences,    # [N, Tdec] índices (próximo token)\n",
        "    pad_idx=0\n",
        ")\n",
        "\n",
        "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
        "print(\"encoder_input_size:\", encoder_input_size)\n",
        "\n",
        "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
        "print(\"decoder_input_size:\", decoder_input_size)\n",
        "\n",
        "print(\"Output dim (vocab_out):\", num_words_output)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "print(\"Tamaño train:\", len(train_set))\n",
        "print(\"Tamaño valid:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True,  pin_memory=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUDPZeuAU1RI",
        "outputId": "52b45999-e85d-412e-c7fa-c61d98293e74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_size: 47\n",
            "decoder_input_size: 50\n",
            "Output dim (vocab_out): 15000\n",
            "Tamaño train: 48000\n",
            "Tamaño valid: 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OcT-DLzkHS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3483d5ce-59f2-4ca7-fafa-a87dd28a274c"
      },
      "source": [
        "# Descargar los embeddings desde un google drive (es la forma más rápida)\n",
        "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
        "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
        "import os\n",
        "import gdown\n",
        "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
        "    output = 'gloveembedding.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los embeddings gloveembedding.pkl ya están descargados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqtV8GpkSc8"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mosj2-x-kXBK"
      },
      "source": [
        "# Por una cuestion de RAM se utilizará los embeddings de Glove de dimension 50\n",
        "model_embeddings = GloveEmbeddings()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9FS8ca1ke_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4fa314-2bb4-4710-bb8d-e4afbf6926fb"
      },
      "source": [
        "# Crear la Embedding matrix de las secuencias\n",
        "# en ingles\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provienen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q3U_WmEYRdH",
        "outputId": "8558dba4-743a-4333-b30c-ffb0ff69dfaf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10692"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpzJODHBlAtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fe0cd4-4285-4f17-dbc0-3293465bbd97"
      },
      "source": [
        "# Dimensión de los embeddings de la secuencia en ingles\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10692, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_words_needed = int(encoder_input_sequences.max()) + 1\n",
        "if nb_words_needed > nb_words:\n",
        "    rows_to_add = nb_words_needed - nb_words\n",
        "    import numpy as np\n",
        "    extra = np.zeros((rows_to_add, embed_dim), dtype=embedding_matrix.dtype)  # o randn*1e-3\n",
        "    embedding_matrix = np.vstack([embedding_matrix, extra])\n",
        "    nb_words = nb_words_needed\n"
      ],
      "metadata": {
        "id": "Pr5ma2EF7zya"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ05swBR71bO",
        "outputId": "ea1919fe-8d9a-4d4a-c51a-18f3e0937e4f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10693"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# ====== HYPERPARÁMETROS (mismos nombres que en Keras) ======\n",
        "n_units = 128\n",
        "# nb_words, embed_dim, embedding_matrix, max_input_len,\n",
        "# num_words_output, max_out_len deben existir como en tu notebook.\n",
        "\n",
        "# ====== INICIALIZACIONES \"estilo Keras\" ======\n",
        "def glorot_uniform_(w):\n",
        "    fan_in = w.size(1)\n",
        "    fan_out = w.size(0) // 4  # por gate, pero usamos el total para el mismo límite\n",
        "    # Usamos fan_in+fan_out como en Glorot; PyTorch concatena 4 gates en dim=0\n",
        "    limit = math.sqrt(6.0 / (fan_in + fan_out))\n",
        "    with torch.no_grad():\n",
        "        w.uniform_(-limit, limit)\n",
        "\n",
        "def orthogonal_per_gate_(w, hidden_size):\n",
        "    # w shape: (4*hidden, hidden). Keras hace orthogonal por gate.\n",
        "    with torch.no_grad():\n",
        "        for g in range(4):\n",
        "            start = g * hidden_size\n",
        "            end = (g + 1) * hidden_size\n",
        "            nn.init.orthogonal_(w[start:end, :])\n",
        "\n",
        "def set_forget_bias_keras_(bias, hidden_size):\n",
        "    # bias shape: (4*hidden,)\n",
        "    # Keras pone forget gate bias = 1\n",
        "    with torch.no_grad():\n",
        "        bias.zero_()\n",
        "        bias[hidden_size:2*hidden_size] = 1.0\n",
        "\n",
        "# ====== LSTM con init estilo Keras y \"single bias\" ======\n",
        "def keras_like_lstm_(lstm: nn.LSTM, input_size, hidden_size):\n",
        "    assert lstm.input_size == input_size and lstm.hidden_size == hidden_size\n",
        "    # Pesos entrada (W) -> glorot_uniform\n",
        "    glorot_uniform_(lstm.weight_ih_l0)\n",
        "    # Pesos recurrentes (U) -> orthogonal por gate\n",
        "    orthogonal_per_gate_(lstm.weight_hh_l0, hidden_size)\n",
        "    # Bias: usamos sólo bias_ih como \"bias único\" (como Keras)\n",
        "    set_forget_bias_keras_(lstm.bias_ih_l0, hidden_size)\n",
        "    with torch.no_grad():\n",
        "        lstm.bias_hh_l0.zero_()\n",
        "    lstm.bias_hh_l0.requires_grad = False  # no entrenable, emula \"un solo bias\"\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, nb_words, embed_dim, embedding_matrix, n_units):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(nb_words, embed_dim, padding_idx=0)\n",
        "        # cargar y congelar\n",
        "        with torch.no_grad():\n",
        "            self.embedding.weight.copy_(torch.from_numpy(embedding_matrix).to(self.embedding.weight.device))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=n_units,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bias=True  # tendremos bias_ih entrenable y bias_hh congelado en 0\n",
        "        )\n",
        "        keras_like_lstm_(self.lstm, embed_dim, n_units)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T_enc] (Long)\n",
        "        x = self.embedding(x)           # [B, T_enc, E]\n",
        "        out, (h, c) = self.lstm(x)      # h,c: [1, B, H]\n",
        "        return (h, c)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_words_output, n_units, max_out_len):\n",
        "        super().__init__()\n",
        "        # En Keras: decoder Embedding output_dim = n_units\n",
        "        self.embedding = nn.Embedding(num_words_output, n_units, padding_idx=0)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=n_units,     # <- igual a Keras\n",
        "            hidden_size=n_units,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bias=True\n",
        "        )\n",
        "        keras_like_lstm_(self.lstm, n_units, n_units)\n",
        "\n",
        "        # Dense (time-distributed): misma capa compartida en todos los pasos\n",
        "        self.fc = nn.Linear(n_units, num_words_output)\n",
        "\n",
        "    def forward(self, y_in, state):\n",
        "        # y_in: [B, T_dec] (Long), state = (h, c) del encoder\n",
        "        y = self.embedding(y_in)            # [B, T_dec, H]\n",
        "        out, (h, c) = self.lstm(y, state)   # out: [B, T_dec, H]\n",
        "        logits = self.fc(out)               # [B, T_dec, V]\n",
        "        return logits, (h, c)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, encoder_inputs, decoder_inputs):\n",
        "        state = self.encoder(encoder_inputs)\n",
        "        logits, _ = self.decoder(decoder_inputs, state)\n",
        "        # logits: [B, T_dec, V] (equivalente a salida del Dense en Keras)\n",
        "        return logits\n",
        "\n",
        "# ====== Construcción del modelo (mismos símbolos que en Keras) ======\n",
        "# Supone que ya se tiene: nb_words, embed_dim, embedding_matrix, num_words_output, max_input_len, max_out_len.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(nb_words, embed_dim, embedding_matrix, n_units)\n",
        "decoder = Decoder(num_words_output, n_units, max_out_len)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "# ====== Ejemplo de \"compilación\" y pérdida (equivalente conceptual) ======\n",
        "# En Keras se usaba 'categorical_crossentropy' con one-hot. En PyTorch:\n",
        "# - usar CrossEntropyLoss sobre logits y targets como índices (sin softmax).\n",
        "criterion = nn.CrossEntropyLoss()  # ignorá padding si usás 0\n",
        "pad_idx = 0\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-7)\n",
        "\n",
        "# ====== Ejemplo de forward ======\n",
        "# encoder_inputs: LongTensor [B, T_enc], decoder_inputs: LongTensor [B, T_dec]\n",
        "# logits = model(encoder_inputs, decoder_inputs)  # [B, T_dec, V]\n",
        "# loss = criterion(logits.view(-1, num_words_output), target_indices.view(-1))\n",
        "# loss.backward(); optimizer.step()"
      ],
      "metadata": {
        "id": "S7KfWvFXmN9H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "B = 2  # batch chico para el summary\n",
        "\n",
        "# Tensores de ejemplo EN EL MISMO DEVICE DEL MODELO y con dtype=Long\n",
        "dummy_enc = torch.randint(0, nb_words,        (B, max_input_len),  device=device, dtype=torch.long)\n",
        "dummy_dec = torch.randint(0, num_words_output,(B, max_out_len),    device=device, dtype=torch.long)\n",
        "\n",
        "# Para modelos con múltiples entradas, pasar una tupla en input_data\n",
        "summary(model,\n",
        "        input_data=(dummy_enc, dummy_dec),\n",
        "        device=device,                 # fuerza a ejecutar en ese device\n",
        "        depth=3,                       # opcional\n",
        "        col_names=(\"input_size\",\"output_size\",\"num_params\",\"trainable\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2ljfUgDrofn",
        "outputId": "2392846d-4fa5-4186-896d-32cc538c9ae6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Trainable\n",
              "============================================================================================================================================\n",
              "Seq2Seq                                  [2, 47]                   [2, 50, 15000]            --                        Partial\n",
              "├─Encoder: 1-1                           [2, 47]                   [1, 2, 128]               --                        Partial\n",
              "│    └─Embedding: 2-1                    [2, 47]                   [2, 47, 50]               (534,650)                 False\n",
              "│    └─LSTM: 2-2                         [2, 47, 50]               [2, 47, 128]              92,160                    Partial\n",
              "├─Decoder: 1-2                           [2, 50]                   [2, 50, 15000]            --                        Partial\n",
              "│    └─Embedding: 2-3                    [2, 50]                   [2, 50, 128]              1,920,000                 True\n",
              "│    └─LSTM: 2-4                         [2, 50, 128]              [2, 50, 128]              132,096                   Partial\n",
              "│    └─Linear: 2-5                       [2, 50, 128]              [2, 50, 15000]            1,935,000                 True\n",
              "============================================================================================================================================\n",
              "Total params: 4,613,906\n",
              "Trainable params: 4,078,232\n",
              "Non-trainable params: 535,674\n",
              "Total mult-adds (Units.MEGABYTES): 30.65\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 12.34\n",
              "Params size (MB): 18.46\n",
              "Estimated Total Size (MB): 30.80\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def token_accuracy_incl_pad(logits, y_true):\n",
        "    # logits: [B, T, V]; y_true: [B, T] (Long)\n",
        "    pred = logits.argmax(dim=-1)     # [B, T]\n",
        "    return (pred == y_true).float().mean()"
      ],
      "metadata": {
        "id": "Ob8XZzqZ2AAC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=15, device=None,\n",
        "          metric_fn=token_accuracy_incl_pad, print_per_epoch=True):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    hist = {\"loss\": [], \"accuracy\": [], \"val_loss\": [], \"val_accuracy\": []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ===== TRAIN =====\n",
        "        model.train()\n",
        "        ep_loss = 0.0\n",
        "        ep_acc  = 0.0\n",
        "        for enc_in, dec_in, y_true in train_loader:\n",
        "            enc_in = enc_in.to(device).long()\n",
        "            dec_in = dec_in.to(device).long()\n",
        "            y_true = y_true.to(device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(enc_in, dec_in)      # [B, T, V]\n",
        "            B, T, V = logits.shape\n",
        "            loss = criterion(logits.reshape(B*T, V), y_true.reshape(B*T))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            ep_loss += loss.item()\n",
        "            ep_acc  += metric_fn(logits, y_true).item()\n",
        "\n",
        "        ep_loss /= len(train_loader)\n",
        "        ep_acc  /= len(train_loader)\n",
        "        hist[\"loss\"].append(ep_loss)\n",
        "        hist[\"accuracy\"].append(ep_acc)\n",
        "\n",
        "        # ===== VALID =====\n",
        "        model.eval()\n",
        "        v_loss = 0.0\n",
        "        v_acc  = 0.0\n",
        "        with torch.no_grad():\n",
        "            for enc_in, dec_in, y_true in valid_loader:\n",
        "                enc_in = enc_in.to(device).long()\n",
        "                dec_in = dec_in.to(device).long()\n",
        "                y_true = y_true.to(device).long()\n",
        "\n",
        "                logits = model(enc_in, dec_in)\n",
        "                B, T, V = logits.shape\n",
        "                loss = criterion(logits.reshape(B*T, V), y_true.reshape(B*T))\n",
        "\n",
        "                v_loss += loss.item()\n",
        "                v_acc  += metric_fn(logits, y_true).item()\n",
        "\n",
        "        v_loss /= len(valid_loader)\n",
        "        v_acc  /= len(valid_loader)\n",
        "        hist[\"val_loss\"].append(v_loss)\n",
        "        hist[\"val_accuracy\"].append(v_acc)\n",
        "\n",
        "        if print_per_epoch:\n",
        "            print(f\"Epoch {epoch+1:03d}/{epochs} \"\n",
        "                  f\"- Train loss {ep_loss:.4f} - Train acc {ep_acc:.4f} \"\n",
        "                  f\"- Valid loss {v_loss:.4f} - Valid acc {v_acc:.4f}\")\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "t0YDjhY6tZKC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "history = train(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    epochs=15,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDB0KWIegt8s",
        "outputId": "2f82c73e-f2c7-4499-a1e3-df1bbee257cc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001/15 - Train loss 0.8844 - Train acc 0.8827 - Valid loss 0.6626 - Valid acc 0.8967\n",
            "Epoch 002/15 - Train loss 0.6269 - Train acc 0.8994 - Valid loss 0.5933 - Valid acc 0.9024\n",
            "Epoch 003/15 - Train loss 0.5591 - Train acc 0.9046 - Valid loss 0.5589 - Valid acc 0.9059\n",
            "Epoch 004/15 - Train loss 0.5121 - Train acc 0.9081 - Valid loss 0.5386 - Valid acc 0.9081\n",
            "Epoch 005/15 - Train loss 0.4753 - Train acc 0.9109 - Valid loss 0.5269 - Valid acc 0.9096\n",
            "Epoch 006/15 - Train loss 0.4448 - Train acc 0.9136 - Valid loss 0.5187 - Valid acc 0.9105\n",
            "Epoch 007/15 - Train loss 0.4182 - Train acc 0.9162 - Valid loss 0.5137 - Valid acc 0.9111\n",
            "Epoch 008/15 - Train loss 0.3952 - Train acc 0.9188 - Valid loss 0.5119 - Valid acc 0.9117\n",
            "Epoch 009/15 - Train loss 0.3745 - Train acc 0.9215 - Valid loss 0.5107 - Valid acc 0.9123\n",
            "Epoch 010/15 - Train loss 0.3561 - Train acc 0.9242 - Valid loss 0.5103 - Valid acc 0.9128\n",
            "Epoch 011/15 - Train loss 0.3396 - Train acc 0.9267 - Valid loss 0.5108 - Valid acc 0.9130\n",
            "Epoch 012/15 - Train loss 0.3246 - Train acc 0.9291 - Valid loss 0.5137 - Valid acc 0.9131\n",
            "Epoch 013/15 - Train loss 0.3111 - Train acc 0.9316 - Valid loss 0.5154 - Valid acc 0.9135\n",
            "Epoch 014/15 - Train loss 0.2986 - Train acc 0.9337 - Valid loss 0.5187 - Valid acc 0.9132\n",
            "Epoch 015/15 - Train loss 0.2872 - Train acc 0.9358 - Valid loss 0.5218 - Valid acc 0.9134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count = range(1, len(history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "pZzm3tx059Zv",
        "outputId": "8e17ed04-a1a7-4104-fd31-4000ae251051"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnkl3mSpsU_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c7e58f6c-dd3d-4e46-eddd-69941154f6e6"
      },
      "source": [
        "'''\n",
        "Step 1:\n",
        "A deal is a deal -> Encoder -> enc(h1,c1)\n",
        "\n",
        "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
        "\n",
        "step 2:\n",
        "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
        "\n",
        "step 3:\n",
        "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
        "\n",
        "step 4:\n",
        "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
        "\n",
        "step 5:\n",
        "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
        "\n",
        "step 6:\n",
        "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
        "'''"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nStep 1:\\nA deal is a deal -> Encoder -> enc(h1,c1)\\n\\nenc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\\n\\nstep 2:\\ndec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\\n\\nstep 3:\\ndec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\\n\\nstep 4:\\ndec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\\n\\nstep 5:\\ndec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\\n\\nstep 6:\\ndec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71XeCtfYmOFx"
      },
      "source": [
        "# Armar los conversores de indice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def translate_sentence(input_seq, model, word2idx_outputs, idx2word_target, max_out_len, device):\n",
        "    \"\"\"\n",
        "    input_seq: array/list/torch.Tensor con ids de la oración fuente [T_enc]\n",
        "    model: tu Seq2Seq ya cargado en 'device'\n",
        "    word2idx_outputs: dict con '<sos>' y '<eos>'\n",
        "    idx2word_target: dict id->palabra del vocab de salida\n",
        "    max_out_len: longitud máxima a decodificar\n",
        "    device: torch.device\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    sos = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "\n",
        "    # --- preparar encoder input [1, T_enc] como Long en device\n",
        "    if isinstance(input_seq, np.ndarray):\n",
        "        enc = torch.from_numpy(input_seq.astype(np.int64))\n",
        "    else:\n",
        "        enc = torch.as_tensor(input_seq, dtype=torch.long)\n",
        "    if enc.dim() == 1:\n",
        "        enc = enc.unsqueeze(0)  # [1, T_enc]\n",
        "    enc = enc.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # estados iniciales del decoder\n",
        "        prev_state = model.encoder(enc)                 # (h,c) con shapes [1, 1, H]\n",
        "\n",
        "        # primer token de entrada al decoder: <sos>\n",
        "        tgt = torch.tensor([[sos]], dtype=torch.long, device=device)  # [1,1]\n",
        "\n",
        "        output_words = []\n",
        "        for _ in range(max_out_len):\n",
        "            logits, prev_state = model.decoder(tgt, prev_state)   # logits: [1, 1, V]\n",
        "\n",
        "            # tomar el último paso temporal y argmax sobre vocab\n",
        "            next_token = logits[:, -1, :].argmax(dim=-1)          # [1]\n",
        "            idx = next_token.item()\n",
        "\n",
        "            if idx == eos:\n",
        "                break\n",
        "            # opcional: ignorar PAD(0) y <sos> si aparecen\n",
        "            if idx != 0 and idx != sos:\n",
        "                # Check if the predicted index is in the vocabulary\n",
        "                if idx in idx2word_target:\n",
        "                    output_words.append(idx2word_target[idx])\n",
        "                else:\n",
        "                    # Handle cases where the predicted index is not in the vocabulary\n",
        "                    output_words.append(f'[UNK:{idx}]') # Or some other indicator\n",
        "\n",
        "\n",
        "            # realimentar el token predicho al decoder\n",
        "            tgt = next_token.view(1, 1)                           # [1,1]\n",
        "\n",
        "    return \" \".join(output_words)"
      ],
      "metadata": {
        "id": "UMpI-I5s_EGU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducción =========\n",
        "input_test = \"My mother say hi.\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representación en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud máxima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducción\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ5uslBu_r2T",
        "outputId": "bc960d28-81d1-487c-89e5-76dfc386a790"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: My mother say hi.\n",
            "Representación en vector de tokens de ids: [18, 206, 130, 2574]\n",
            "Padding del vector: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0   18  206  130 2574]]\n",
            "Response: mi madre se casó\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducción =========\n",
        "input_test = \"I like dogs and cats.\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representación en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud máxima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducción\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN-rIib1ad2Y",
        "outputId": "d77d0183-d3c4-4df7-cefc-9fd9c11a821b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I like dogs and cats.\n",
            "Representación en vector de tokens de ids: [2, 35, 575, 34, 791]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   2  35 575  34 791]]\n",
            "Response: me gusta el café\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducción =========\n",
        "input_test = \"I wish you happy new year.\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representación en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud máxima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducción\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsPWQEsYbrVV",
        "outputId": "82aabcfb-c481-41c5-8c68-147ae4336c2e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I wish you happy new year.\n",
            "Representación en vector de tokens de ids: [2, 311, 4, 191, 122, 232]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   2 311   4 191 122 232]]\n",
            "Response: si no te hubiera sabido nada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducción =========\n",
        "input_test = \"Today is a beautiful day.\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representación en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud máxima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducción\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLpFUeXmb68n",
        "outputId": "35a3cd59-7c43-4518-d92b-4f84a8f053b9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Today is a beautiful day.\n",
            "Representación en vector de tokens de ids: [143, 7, 6, 248, 105]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0 143   7   6 248 105]]\n",
            "Response: tom es un día soleado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducción =========\n",
        "input_test = \"The sky is blue\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representación en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud máxima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducción\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw5gLwBNb9ii",
        "outputId": "2a6b473f-80cd-4166-a20f-1abd79b38961"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: The sky is blue\n",
            "Representación en vector de tokens de ids: [1, 913, 7, 804]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   1 913   7 804]]\n",
            "Response: el cielo es muy larga\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desafío 4"
      ],
      "metadata": {
        "id": "YrFtG0SHVE8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Replicar el modelo en Pytorch"
      ],
      "metadata": {
        "id": "bb3ZM3ImVejE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se replicó en Pytorch el modelo provisto en Keras con los mismos parámetros, buscando obtener los mismos resultados. Se tomó como base el modelo en Keras, otro modelo provisto en clase en Pytorch, y se utilizó asistencia de un modelo de lenguaje para lograr la correspondencia entre ambos modelos.\n",
        "\n",
        "Dado que las LSTM de Keras y Pytorch no son idénticas, fue necesario agregar algunas funciones (glorot uniform, orthogonal per gate, set bias) para luego definir Keras_like_LSTM, y así poder replicar el modelo de Keras.\n",
        "\n",
        "Finalmente, utilizando los mismos parámetros, se logró alcanzar una arquitectura similar:\n",
        "\n",
        "En Keras:\n",
        "\n",
        "* Total params: 1,886,336\n",
        "* Trainable params: 1,693,786\n",
        "* Non-trainable params: 192,550\n",
        "\n",
        "\n",
        "En Pytorch:\n",
        "* Total params: 1,887,410\n",
        "* Trainable params: 1,693,786\n",
        "* Non-trainable params: 193,624\n",
        "\n",
        "Al realizar el entrenamiento, se obtiene una accuracy en validación de 0.7153, mientras que en el modelo con Keras se alcanzaba un 0.7128. Con estos resultados, se considera que los modelos son suficientemente similares para continuar con el desarrollo del trabajo."
      ],
      "metadata": {
        "id": "3ZikvuKCVcW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Pruebas con el modelo en Pytorch"
      ],
      "metadata": {
        "id": "PEfialZT9lJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realizaron distintas pruebas modificando la cantidad de datos de entrenamiento, la cantidad de palabras en el vocabulario, los tamaños de secuencias de entrada y salida, y la cantidad de neuronas de las capas recurrentes.\n",
        "\n",
        "En cada caso, se evaluó la accuracy de validación, y se realizó la traducción de 5 frases diferentes para evaluar el desempeño del modelo. Se eligieron frases cortas y con palabras comunes, que idealmente deberían traducirse correctamente. Las frases son:\n",
        "\n",
        "* My mother say hi (frase de prueba del modelo original en Keras)\n",
        "* I like dogs and cats\n",
        "* I wish you happy new year\n",
        "* Today is a beautiful day\n",
        "* The sky is blue\n",
        "\n",
        "Es importante destacar que los parámetros se fueron ajustando de manera gradual, ya que al liberarlos demasiado se obtuvieron problemas relacionados a la memoria y la ejecución fallaba. Para la realización de cada prueba sin problemas, fue necesario reiniciar todo el entorno de ejecución y comenzar desde cero.\n",
        "\n",
        "En la tabla a continuación se muestra un resumen de los parámetros modificados y los resultados obtenidos en cada caso, sin incluir los casos que fallaron."
      ],
      "metadata": {
        "id": "hbnvCzRjXz3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| N° prueba | MAX_NUM_SENTENCES | MAX_VOCAB_SIZE | max_input_len | max_output_len | n_units | Valid acc | My mother say hi             | I like dogs and cats                                    | i wish you happy new year                    | Today is a beautiful day             | The sky is blue                     |\n",
        "|-----------|---------------------|----------------|---------------|---------------|---------|-----------|------------------------------|---------------------------------------------------------|---------------------------------------------|--------------------------------------|--------------------------------------|\n",
        "| 1         | 6000               | 8000           | 16            | 18            | 128     | 0.7153    | ella se ha ido               | -                                                       | -                                           | -                                    | -                                    |\n",
        "| 2         | 12000              | 8000           | 16            | 18            | 128     | 0.7306    | mi mamá me gusta            | me gusta el filete medianamente cocido                  | te traje aspirina                           | tom es un chico tímido              | la situación está sabrosa            |\n",
        "| 3         | 36000              | 8000           | 16            | 18            | 128     | 0.7537    | mi madre se le olvidó el miedo de mary | me gustan los perros                             | ojalá hubieras guardado el nuevo            | tom es un hombre de negocios       | la situación está en llamas         |\n",
        "| 4         | 36000              | 16000          | 16            | 18            | 128     | 0.7428    | mi madre tiene un minuto    | me gusta el café y azúcar                             | te quiero ayudarte                           | tom es un conductor veloz          | la verdad es que es                 |\n",
        "| 5         | 36000              | 16000          | 32            | 36            | 128     | 0.8708    | mi madre me ha arañado      | me gusta el café                                      | no te voy a casa mañana                     | tom es un chico formal             | tom habla francés                   |\n",
        "| 6         | 38000              | 16000          | 32            | 36            | 128     | 0.8725    | mi madre ha comenzado a casa| me gusta el café                                      | te quiero que te guste                       | tom es un buen trabajo            | el cielo está despejado            |\n",
        "| 7         | 45000              | 16000          | 32            | 36            | 128     | 0.8741    | mary se le acercó          | me gustan las almendras que christie que no           | quiero que tú estabas aquí                   | tom es un chico tímido            | el cielo está despejado            |\n",
        "| 8         | 50000              | 18000          | 47            | 48            | 128     | 0.9057    | mary se casó con él        | me gusta el café                                      | ayer no te habría dicho                      | tom es un buen médico             | el cielo está despejado            |\n",
        "| 9         | 60000              | 18000          | 32            | 36            | 128     | 0.8777    | mi madre tiene que decir   | me gusta el café                                      | te ayudo con ustedes                         | tom es un buen atleta            | la historia es extraña            |\n",
        "| 10        | 60000              | 18000          | 47            | 50            | 128     | 0.9122    | mi madre me ayudó         | me gusta el inglés y el alemán                       | te haré daño                                | tom es un chico astuto          | la historia es extraña            |\n",
        "| 11        | 60000              | 15000          | 47            | 50            | 128     | 0.9134    | mi madre se casó         | me gusta el café                                      | si no te hubiera sabido nada                 | tom es un día soleado          | el cielo es muy larga            |\n",
        "| 12        | 70000              | 15000          | 47            | 48            | 128     | 0.9104    | mi madre ha perdido      | me gusta el café                                      | te quiero que seas feliz                     | tom es un perro grande        | el cielo está despejado         |\n",
        "| 13        | 60000              | 15000          | 47            | 48            | 64      | 0.9053    | mi hermano se está quemando | me gusta el café                                   | te esperaré aquí                              | tom es un buen trabajo       | tom se está quedando en boston |\n",
        "| 14        | 60000              | 15000          | 47            | 48            | 256     | 0.9115    | mi madre me enseñó      | me gusta el café y el día                          | te deseo que no vayas                         | tom es un conductor veloz   | la situación es desagradable  |\n",
        "| 15        | 60000              | 15000          | 47            | 48            | 512     | 0.9131    | mi madre puso su mano | me gusta el helado de chocolate                | te quiero su respeto                          | tom es un chico malo        | el cielo es azul               |\n"
      ],
      "metadata": {
        "id": "fSdLVxEgMNnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2a - Extender el entrenamiento a más datos y tamaños de secuencias mayores"
      ],
      "metadata": {
        "id": "tamIf5QXVYyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aumentó gradualmente la cantidad de datos de entrada, el tamaño del vocabulario y el tamaño de las secuencias de entrada y de salida.\n",
        "\n",
        "En todos los casos se observó que a mayor cantidad de datos y tamaño de secuencias, mayor accuracy de validación. Sin embargo, si se aumenta demasiado se obtienen problemas con la memoria y no se puede finalizar la ejecución, por lo que se fue aumentando de a un parámetro por vez.\n",
        "\n",
        "Los mayores incrementos en accuracy se observaron al modificar el tamaño de las secuencias de entrada y salida.\n",
        "\n",
        "Es importante destacar que se evaluó en conjunto la accuracy de validación y la traducción de las 5 frases, ya que en algunos casos la mejora en accuracy no se condice con una mejora en la traducción.\n",
        "\n",
        "Esto ocurre entre las ejecuciones 4 y 5, donde se observa un incremento importante en accuracy, pero no una mejora en las traducciones. Por ejemplo, pasa de \"me gusta el café y azúcar\" a \"me gusta el café\", cuando la estructura de la frase incluye dos sustantivos (\"i like dogs and cats\"). En \"i wish you happy new year\", se había obtenido una frase que comenzaba con \"te quiero\" (más similar a un \"te deseo feliz año nuevo\"), y luego se obtiene una frase sin ninguna relación con la original (\"no te voy a casa mañana\").\n",
        "\n",
        "En la prueba 6, por ejemplo, se obtuvo una accuracy muy similar a la prueba anterior y a la siguiente, pero se destaca por lograr buenos resultados en la traducción: \"mi madre\", \"me gusta\", \"te quiero\" y \"el cielo está despejado\".\n",
        "\n",
        "En conjunto, los mejores resultados se obtuvieron en las ejecuciones 11 y 12, llevando al máximo posible (sin fallas) la cantidad de sentencias utilizadas y los tamaños de secuencias. Se obtiene una accuracy de validación mayor a 0.91 en ambos casos, y las mejores traducciones de las frases de prueba. La ejecución 11 se destaca ya que es la única vez que se obtiene \"es un día soleado\" para la frase 4, que suele fallar en el resto de las ejecuciones."
      ],
      "metadata": {
        "id": "W17Fn5HfEw3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2b - Explorar el impacto de la cantidad de neuronas en las capas recurrentes"
      ],
      "metadata": {
        "id": "kC2FdURlJfDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que se definieron la cantidad de sentencias, tamaño de vocabulario y tamaño de secuencias, se realizaron pruebas con 64, 128, 256 y 512 neuronas en las capas recurrentes, que pueden observarse en la tabla.\n",
        "\n",
        "Si bien la accuracy de validación obtenida se relaciona directamente con la cantidad de neuronas, la diferencia en los valores es mínima, y no se traduce directamente en un mejor desempeño en las frases de prueba.\n",
        "\n",
        "Al reducir el tamaño a 64 se observa que empeoran los resultados con las frases de prueba (\"mi hermano\", \"tom se está quedando en boston\"), pero al aumentar a 256 y 512 no se observa que la mejora sea sustancial. Esto probablemente se relaciona con que al tener más parámetros entrenables se debería aumentar la cantidad de datos de entrada, y esto no es posible por los límites de memoria.\n",
        "\n",
        "Al modificar la cantidad de neuronas se observa que se modifican en la misma medida la cantidad de parámetros del modelo.\n",
        "\n",
        "Por otro lado, a medida que se aumenta la cantidad de neuronas aumenta considerablemente el tiempo que lleva el entrenamiento. Sin embargo, se observa que la curva de accuracy de validación alcanza un valor estable más rápidamente, por lo que se podría reducir la cantidad de épocas para reducir el tiempo de entrenamiento.\n",
        "\n",
        "Observando todos los resultados en conjunto y los tiempos de entrenamiento, se decidió conservar la cantidad de neuronas iniciales de 128."
      ],
      "metadata": {
        "id": "oqKN_FwpJlOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2c - Mostrar 5 ejemplos de traducciones generadas\n",
        "\n",
        "Se muestran los resultados en la tabla y en la sección \"5 - Inferencia\"."
      ],
      "metadata": {
        "id": "AdxapOdOL2jn"
      }
    }
  ]
}