{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nataliaespector/CEIA_TPs_Procesamiento_Lenguaje_Natural_1/blob/main/Espector_PLN_Desaf%C3%ADo_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Traductor\n",
        "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objeto es utilizar datos disponibles de Anki de traducciones de texto en diferentes idiomas. Se construir√° un modelo traductor seq2seq utilizando encoder-decoder.\\\n",
        "[LINK](https://www.manythings.org/anki/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgYatMIdk_eT",
        "outputId": "ad3bb00c-0eac-478d-ccb7-fdcdf53d66b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchsummar actualmente tiene un problema con las LSTM, por eso\n",
        "# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n",
        "!pip3 install torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYpIWGaXxfKe",
        "outputId": "9e1c0aba-8600-4d34-9795-f0ab0ba69ae8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ],
      "metadata": {
        "id": "GHFPS5KNxgR9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - Datos"
      ],
      "metadata": {
        "id": "5BFiCH8nxoIY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb54494-1ffa-42ba-c14d-59acf5e49d9b"
      },
      "source": [
        "# Descargar la carpeta de dataset\n",
        "\n",
        "import os\n",
        "if os.access('spa-eng', os.F_OK) is False:\n",
        "    if os.access('spa-eng.zip', os.F_OK) is False:\n",
        "        !curl -L -o 'spa-eng.zip' 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "    !unzip -q spa-eng.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9aNLZBDtA5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7d9d89-7d86-48e1-8365-cf405da4a771"
      },
      "source": [
        "# dataset_file\n",
        "\n",
        "text_file = \"./spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "# Por limitaciones de RAM no se leen todas las filas\n",
        "MAX_NUM_SENTENCES = 60000\n",
        "\n",
        "# Mezclar el dataset, forzar semilla siempre igual\n",
        "np.random.seed([40])\n",
        "np.random.shuffle(lines)\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "count = 0\n",
        "\n",
        "for line in lines:\n",
        "    count += 1\n",
        "    if count > MAX_NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "    if '\\t' not in line:\n",
        "        continue\n",
        "\n",
        "    # Input sentence --> eng\n",
        "    # output --> spa\n",
        "    input_sentence, output = line.rstrip().split('\\t')\n",
        "\n",
        "    # output sentence (decoder_output) tiene <eos>\n",
        "    output_sentence = output + ' <eos>'\n",
        "    # output sentence input (decoder_input) tiene <sos>\n",
        "    output_sentence_input = '<sos> ' + output\n",
        "\n",
        "    input_sentences.append(input_sentence)\n",
        "    output_sentences.append(output_sentence)\n",
        "    output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows disponibles:\", len(lines))\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows disponibles: 118964\n",
            "Cantidad de rows utilizadas: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93IGMKFb73q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f617a0e3-b4f4-4689-8662-019f85001b49"
      },
      "source": [
        "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('A deal is a deal.',\n",
              " 'Un trato es un trato. <eos>',\n",
              " '<sos> Un trato es un trato.')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WAZGOTfGyha"
      },
      "source": [
        "# Definir el tama√±o m√°ximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 15000"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF1W6peoFGXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720f041a-af32-4824-e249-8ed5553e4369"
      },
      "source": [
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una m√°xima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "\n",
        "# tokenizador de ingl√©s\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada m√°s larga:\", max_input_len)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 10692\n",
            "Sentencia de entrada m√°s larga: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBzdKiTVIBYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932488a9-e62f-4949-df2e-b3c59e2f570b"
      },
      "source": [
        "# A los filtros de s√≠mbolos del Tokenizer agregamos el \"¬ø\",\n",
        "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "# tokenizador de espa√±ol\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¬ø?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida m√°s larga:\", max_out_len)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 19614\n",
            "Sentencia de salida m√°s larga: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqb8ZJ4sJHgv"
      },
      "source": [
        "Como era de esperarse, las sentencias en castellano son m√°s largas que en ingl√©s, y lo mismo sucede con su vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgLC706EQx3p"
      },
      "source": [
        "# Por una cuestion de que no explote la RAM se limitar√° el tama√±o de las sentencias de entrada\n",
        "# a la mitad:\n",
        "max_input_len = 47\n",
        "max_out_len = 50"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOn9N57IuYz"
      },
      "source": [
        "A la hora de realizar padding es importante tener en cuenta que en el encoder los ceros se agregan al comienzo y en el decoder al final. Esto es porque la salida del encoder est√° basado en las √∫ltimas palabras de la sentencia (son las m√°s importantes), mientras que en el decoder est√° basado en el comienzo de la secuencia de salida ya que es la realimentaci√≥n del sistema y termina con fin de sentencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ob4hAWJkcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6298a5c0-2a72-47d8-bc61-727e16823898"
      },
      "source": [
        "#from torch_helpers import pad_sequences\n",
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows del dataset: 60000\n",
            "encoder_input_sequences shape: (60000, 47)\n",
            "decoder_input_sequences shape: (60000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VySR1pzx9UG",
        "outputId": "dd55f9e2-4ac2-46e9-9c87-48cc094355f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_output_sequences shape: (60000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(decoder_output_sequences).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANTOqJ0WWw-q",
        "outputId": "f55a32ae-6ddf-458b-9d39-4ab355c2a9ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, decoder_output, pad_idx=0):\n",
        "        # Entradas como √≠ndices (Long)\n",
        "        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int64))  # [N, Tenc]\n",
        "        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int64))  # [N, Tdec]\n",
        "\n",
        "        # üîß SALIDA COMO √çNDICES (¬°sin one-hot!)\n",
        "        # decoder_output ya viene como √≠ndices [N, Tdec]\n",
        "        self.decoder_outputs = torch.from_numpy(decoder_output.astype(np.int64))  # [N, Tdec]\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "        self.len = self.decoder_outputs.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Devolvemos todo como Long (√≠ndices)\n",
        "        return (\n",
        "            self.encoder_inputs[index].long(),\n",
        "            self.decoder_inputs[index].long(),\n",
        "            self.decoder_outputs[index].long()\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "SD0bpM32yWfB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = Data(\n",
        "    encoder_input_sequences,     # [N, Tenc] √≠ndices\n",
        "    decoder_input_sequences,     # [N, Tdec] √≠ndices (con <sos> al principio)\n",
        "    decoder_output_sequences,    # [N, Tdec] √≠ndices (pr√≥ximo token)\n",
        "    pad_idx=0\n",
        ")\n",
        "\n",
        "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
        "print(\"encoder_input_size:\", encoder_input_size)\n",
        "\n",
        "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
        "print(\"decoder_input_size:\", decoder_input_size)\n",
        "\n",
        "print(\"Output dim (vocab_out):\", num_words_output)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "print(\"Tama√±o train:\", len(train_set))\n",
        "print(\"Tama√±o valid:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True,  pin_memory=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUDPZeuAU1RI",
        "outputId": "52b45999-e85d-412e-c7fa-c61d98293e74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_size: 47\n",
            "decoder_input_size: 50\n",
            "Output dim (vocab_out): 15000\n",
            "Tama√±o train: 48000\n",
            "Tama√±o valid: 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OcT-DLzkHS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3483d5ce-59f2-4ca7-fafa-a87dd28a274c"
      },
      "source": [
        "# Descargar los embeddings desde un google drive (es la forma m√°s r√°pida)\n",
        "# NOTA: No hay garant√≠a de que estos links perduren, en caso de que no est√©n\n",
        "# disponibles descargar de la p√°gina oficial como se explica en el siguiente bloque\n",
        "import os\n",
        "import gdown\n",
        "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
        "    output = 'gloveembedding.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings gloveembedding.pkl ya est√°n descargados\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los embeddings gloveembedding.pkl ya est√°n descargados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqtV8GpkSc8"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mosj2-x-kXBK"
      },
      "source": [
        "# Por una cuestion de RAM se utilizar√° los embeddings de Glove de dimension 50\n",
        "model_embeddings = GloveEmbeddings()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9FS8ca1ke_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4fa314-2bb4-4710-bb8d-e4afbf6926fb"
      },
      "source": [
        "# Crear la Embedding matrix de las secuencias\n",
        "# en ingles\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provienen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q3U_WmEYRdH",
        "outputId": "8558dba4-743a-4333-b30c-ffb0ff69dfaf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10692"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpzJODHBlAtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fe0cd4-4285-4f17-dbc0-3293465bbd97"
      },
      "source": [
        "# Dimensi√≥n de los embeddings de la secuencia en ingles\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10692, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_words_needed = int(encoder_input_sequences.max()) + 1\n",
        "if nb_words_needed > nb_words:\n",
        "    rows_to_add = nb_words_needed - nb_words\n",
        "    import numpy as np\n",
        "    extra = np.zeros((rows_to_add, embed_dim), dtype=embedding_matrix.dtype)  # o randn*1e-3\n",
        "    embedding_matrix = np.vstack([embedding_matrix, extra])\n",
        "    nb_words = nb_words_needed\n"
      ],
      "metadata": {
        "id": "Pr5ma2EF7zya"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ05swBR71bO",
        "outputId": "ea1919fe-8d9a-4d4a-c51a-18f3e0937e4f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10693"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# ====== HYPERPAR√ÅMETROS (mismos nombres que en Keras) ======\n",
        "n_units = 128\n",
        "# nb_words, embed_dim, embedding_matrix, max_input_len,\n",
        "# num_words_output, max_out_len deben existir como en tu notebook.\n",
        "\n",
        "# ====== INICIALIZACIONES \"estilo Keras\" ======\n",
        "def glorot_uniform_(w):\n",
        "    fan_in = w.size(1)\n",
        "    fan_out = w.size(0) // 4  # por gate, pero usamos el total para el mismo l√≠mite\n",
        "    # Usamos fan_in+fan_out como en Glorot; PyTorch concatena 4 gates en dim=0\n",
        "    limit = math.sqrt(6.0 / (fan_in + fan_out))\n",
        "    with torch.no_grad():\n",
        "        w.uniform_(-limit, limit)\n",
        "\n",
        "def orthogonal_per_gate_(w, hidden_size):\n",
        "    # w shape: (4*hidden, hidden). Keras hace orthogonal por gate.\n",
        "    with torch.no_grad():\n",
        "        for g in range(4):\n",
        "            start = g * hidden_size\n",
        "            end = (g + 1) * hidden_size\n",
        "            nn.init.orthogonal_(w[start:end, :])\n",
        "\n",
        "def set_forget_bias_keras_(bias, hidden_size):\n",
        "    # bias shape: (4*hidden,)\n",
        "    # Keras pone forget gate bias = 1\n",
        "    with torch.no_grad():\n",
        "        bias.zero_()\n",
        "        bias[hidden_size:2*hidden_size] = 1.0\n",
        "\n",
        "# ====== LSTM con init estilo Keras y \"single bias\" ======\n",
        "def keras_like_lstm_(lstm: nn.LSTM, input_size, hidden_size):\n",
        "    assert lstm.input_size == input_size and lstm.hidden_size == hidden_size\n",
        "    # Pesos entrada (W) -> glorot_uniform\n",
        "    glorot_uniform_(lstm.weight_ih_l0)\n",
        "    # Pesos recurrentes (U) -> orthogonal por gate\n",
        "    orthogonal_per_gate_(lstm.weight_hh_l0, hidden_size)\n",
        "    # Bias: usamos s√≥lo bias_ih como \"bias √∫nico\" (como Keras)\n",
        "    set_forget_bias_keras_(lstm.bias_ih_l0, hidden_size)\n",
        "    with torch.no_grad():\n",
        "        lstm.bias_hh_l0.zero_()\n",
        "    lstm.bias_hh_l0.requires_grad = False  # no entrenable, emula \"un solo bias\"\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, nb_words, embed_dim, embedding_matrix, n_units):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(nb_words, embed_dim, padding_idx=0)\n",
        "        # cargar y congelar\n",
        "        with torch.no_grad():\n",
        "            self.embedding.weight.copy_(torch.from_numpy(embedding_matrix).to(self.embedding.weight.device))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=n_units,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bias=True  # tendremos bias_ih entrenable y bias_hh congelado en 0\n",
        "        )\n",
        "        keras_like_lstm_(self.lstm, embed_dim, n_units)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T_enc] (Long)\n",
        "        x = self.embedding(x)           # [B, T_enc, E]\n",
        "        out, (h, c) = self.lstm(x)      # h,c: [1, B, H]\n",
        "        return (h, c)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_words_output, n_units, max_out_len):\n",
        "        super().__init__()\n",
        "        # En Keras: decoder Embedding output_dim = n_units\n",
        "        self.embedding = nn.Embedding(num_words_output, n_units, padding_idx=0)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=n_units,     # <- igual a Keras\n",
        "            hidden_size=n_units,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bias=True\n",
        "        )\n",
        "        keras_like_lstm_(self.lstm, n_units, n_units)\n",
        "\n",
        "        # Dense (time-distributed): misma capa compartida en todos los pasos\n",
        "        self.fc = nn.Linear(n_units, num_words_output)\n",
        "\n",
        "    def forward(self, y_in, state):\n",
        "        # y_in: [B, T_dec] (Long), state = (h, c) del encoder\n",
        "        y = self.embedding(y_in)            # [B, T_dec, H]\n",
        "        out, (h, c) = self.lstm(y, state)   # out: [B, T_dec, H]\n",
        "        logits = self.fc(out)               # [B, T_dec, V]\n",
        "        return logits, (h, c)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, encoder_inputs, decoder_inputs):\n",
        "        state = self.encoder(encoder_inputs)\n",
        "        logits, _ = self.decoder(decoder_inputs, state)\n",
        "        # logits: [B, T_dec, V] (equivalente a salida del Dense en Keras)\n",
        "        return logits\n",
        "\n",
        "# ====== Construcci√≥n del modelo (mismos s√≠mbolos que en Keras) ======\n",
        "# Supone que ya se tiene: nb_words, embed_dim, embedding_matrix, num_words_output, max_input_len, max_out_len.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(nb_words, embed_dim, embedding_matrix, n_units)\n",
        "decoder = Decoder(num_words_output, n_units, max_out_len)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "# ====== Ejemplo de \"compilaci√≥n\" y p√©rdida (equivalente conceptual) ======\n",
        "# En Keras se usaba 'categorical_crossentropy' con one-hot. En PyTorch:\n",
        "# - usar CrossEntropyLoss sobre logits y targets como √≠ndices (sin softmax).\n",
        "criterion = nn.CrossEntropyLoss()  # ignor√° padding si us√°s 0\n",
        "pad_idx = 0\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-7)\n",
        "\n",
        "# ====== Ejemplo de forward ======\n",
        "# encoder_inputs: LongTensor [B, T_enc], decoder_inputs: LongTensor [B, T_dec]\n",
        "# logits = model(encoder_inputs, decoder_inputs)  # [B, T_dec, V]\n",
        "# loss = criterion(logits.view(-1, num_words_output), target_indices.view(-1))\n",
        "# loss.backward(); optimizer.step()"
      ],
      "metadata": {
        "id": "S7KfWvFXmN9H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "B = 2  # batch chico para el summary\n",
        "\n",
        "# Tensores de ejemplo EN EL MISMO DEVICE DEL MODELO y con dtype=Long\n",
        "dummy_enc = torch.randint(0, nb_words,        (B, max_input_len),  device=device, dtype=torch.long)\n",
        "dummy_dec = torch.randint(0, num_words_output,(B, max_out_len),    device=device, dtype=torch.long)\n",
        "\n",
        "# Para modelos con m√∫ltiples entradas, pasar una tupla en input_data\n",
        "summary(model,\n",
        "        input_data=(dummy_enc, dummy_dec),\n",
        "        device=device,                 # fuerza a ejecutar en ese device\n",
        "        depth=3,                       # opcional\n",
        "        col_names=(\"input_size\",\"output_size\",\"num_params\",\"trainable\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2ljfUgDrofn",
        "outputId": "2392846d-4fa5-4186-896d-32cc538c9ae6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Trainable\n",
              "============================================================================================================================================\n",
              "Seq2Seq                                  [2, 47]                   [2, 50, 15000]            --                        Partial\n",
              "‚îú‚îÄEncoder: 1-1                           [2, 47]                   [1, 2, 128]               --                        Partial\n",
              "‚îÇ    ‚îî‚îÄEmbedding: 2-1                    [2, 47]                   [2, 47, 50]               (534,650)                 False\n",
              "‚îÇ    ‚îî‚îÄLSTM: 2-2                         [2, 47, 50]               [2, 47, 128]              92,160                    Partial\n",
              "‚îú‚îÄDecoder: 1-2                           [2, 50]                   [2, 50, 15000]            --                        Partial\n",
              "‚îÇ    ‚îî‚îÄEmbedding: 2-3                    [2, 50]                   [2, 50, 128]              1,920,000                 True\n",
              "‚îÇ    ‚îî‚îÄLSTM: 2-4                         [2, 50, 128]              [2, 50, 128]              132,096                   Partial\n",
              "‚îÇ    ‚îî‚îÄLinear: 2-5                       [2, 50, 128]              [2, 50, 15000]            1,935,000                 True\n",
              "============================================================================================================================================\n",
              "Total params: 4,613,906\n",
              "Trainable params: 4,078,232\n",
              "Non-trainable params: 535,674\n",
              "Total mult-adds (Units.MEGABYTES): 30.65\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 12.34\n",
              "Params size (MB): 18.46\n",
              "Estimated Total Size (MB): 30.80\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def token_accuracy_incl_pad(logits, y_true):\n",
        "    # logits: [B, T, V]; y_true: [B, T] (Long)\n",
        "    pred = logits.argmax(dim=-1)     # [B, T]\n",
        "    return (pred == y_true).float().mean()"
      ],
      "metadata": {
        "id": "Ob8XZzqZ2AAC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=15, device=None,\n",
        "          metric_fn=token_accuracy_incl_pad, print_per_epoch=True):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    hist = {\"loss\": [], \"accuracy\": [], \"val_loss\": [], \"val_accuracy\": []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ===== TRAIN =====\n",
        "        model.train()\n",
        "        ep_loss = 0.0\n",
        "        ep_acc  = 0.0\n",
        "        for enc_in, dec_in, y_true in train_loader:\n",
        "            enc_in = enc_in.to(device).long()\n",
        "            dec_in = dec_in.to(device).long()\n",
        "            y_true = y_true.to(device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(enc_in, dec_in)      # [B, T, V]\n",
        "            B, T, V = logits.shape\n",
        "            loss = criterion(logits.reshape(B*T, V), y_true.reshape(B*T))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            ep_loss += loss.item()\n",
        "            ep_acc  += metric_fn(logits, y_true).item()\n",
        "\n",
        "        ep_loss /= len(train_loader)\n",
        "        ep_acc  /= len(train_loader)\n",
        "        hist[\"loss\"].append(ep_loss)\n",
        "        hist[\"accuracy\"].append(ep_acc)\n",
        "\n",
        "        # ===== VALID =====\n",
        "        model.eval()\n",
        "        v_loss = 0.0\n",
        "        v_acc  = 0.0\n",
        "        with torch.no_grad():\n",
        "            for enc_in, dec_in, y_true in valid_loader:\n",
        "                enc_in = enc_in.to(device).long()\n",
        "                dec_in = dec_in.to(device).long()\n",
        "                y_true = y_true.to(device).long()\n",
        "\n",
        "                logits = model(enc_in, dec_in)\n",
        "                B, T, V = logits.shape\n",
        "                loss = criterion(logits.reshape(B*T, V), y_true.reshape(B*T))\n",
        "\n",
        "                v_loss += loss.item()\n",
        "                v_acc  += metric_fn(logits, y_true).item()\n",
        "\n",
        "        v_loss /= len(valid_loader)\n",
        "        v_acc  /= len(valid_loader)\n",
        "        hist[\"val_loss\"].append(v_loss)\n",
        "        hist[\"val_accuracy\"].append(v_acc)\n",
        "\n",
        "        if print_per_epoch:\n",
        "            print(f\"Epoch {epoch+1:03d}/{epochs} \"\n",
        "                  f\"- Train loss {ep_loss:.4f} - Train acc {ep_acc:.4f} \"\n",
        "                  f\"- Valid loss {v_loss:.4f} - Valid acc {v_acc:.4f}\")\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "t0YDjhY6tZKC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "history = train(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    epochs=15,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDB0KWIegt8s",
        "outputId": "2f82c73e-f2c7-4499-a1e3-df1bbee257cc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001/15 - Train loss 0.8844 - Train acc 0.8827 - Valid loss 0.6626 - Valid acc 0.8967\n",
            "Epoch 002/15 - Train loss 0.6269 - Train acc 0.8994 - Valid loss 0.5933 - Valid acc 0.9024\n",
            "Epoch 003/15 - Train loss 0.5591 - Train acc 0.9046 - Valid loss 0.5589 - Valid acc 0.9059\n",
            "Epoch 004/15 - Train loss 0.5121 - Train acc 0.9081 - Valid loss 0.5386 - Valid acc 0.9081\n",
            "Epoch 005/15 - Train loss 0.4753 - Train acc 0.9109 - Valid loss 0.5269 - Valid acc 0.9096\n",
            "Epoch 006/15 - Train loss 0.4448 - Train acc 0.9136 - Valid loss 0.5187 - Valid acc 0.9105\n",
            "Epoch 007/15 - Train loss 0.4182 - Train acc 0.9162 - Valid loss 0.5137 - Valid acc 0.9111\n",
            "Epoch 008/15 - Train loss 0.3952 - Train acc 0.9188 - Valid loss 0.5119 - Valid acc 0.9117\n",
            "Epoch 009/15 - Train loss 0.3745 - Train acc 0.9215 - Valid loss 0.5107 - Valid acc 0.9123\n",
            "Epoch 010/15 - Train loss 0.3561 - Train acc 0.9242 - Valid loss 0.5103 - Valid acc 0.9128\n",
            "Epoch 011/15 - Train loss 0.3396 - Train acc 0.9267 - Valid loss 0.5108 - Valid acc 0.9130\n",
            "Epoch 012/15 - Train loss 0.3246 - Train acc 0.9291 - Valid loss 0.5137 - Valid acc 0.9131\n",
            "Epoch 013/15 - Train loss 0.3111 - Train acc 0.9316 - Valid loss 0.5154 - Valid acc 0.9135\n",
            "Epoch 014/15 - Train loss 0.2986 - Train acc 0.9337 - Valid loss 0.5187 - Valid acc 0.9132\n",
            "Epoch 015/15 - Train loss 0.2872 - Train acc 0.9358 - Valid loss 0.5218 - Valid acc 0.9134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count = range(1, len(history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "pZzm3tx059Zv",
        "outputId": "8e17ed04-a1a7-4104-fd31-4000ae251051"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnkl3mSpsU_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c7e58f6c-dd3d-4e46-eddd-69941154f6e6"
      },
      "source": [
        "'''\n",
        "Step 1:\n",
        "A deal is a deal -> Encoder -> enc(h1,c1)\n",
        "\n",
        "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
        "\n",
        "step 2:\n",
        "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
        "\n",
        "step 3:\n",
        "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
        "\n",
        "step 4:\n",
        "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
        "\n",
        "step 5:\n",
        "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
        "\n",
        "step 6:\n",
        "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
        "'''"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nStep 1:\\nA deal is a deal -> Encoder -> enc(h1,c1)\\n\\nenc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\\n\\nstep 2:\\ndec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\\n\\nstep 3:\\ndec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\\n\\nstep 4:\\ndec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\\n\\nstep 5:\\ndec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\\n\\nstep 6:\\ndec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71XeCtfYmOFx"
      },
      "source": [
        "# Armar los conversores de indice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def translate_sentence(input_seq, model, word2idx_outputs, idx2word_target, max_out_len, device):\n",
        "    \"\"\"\n",
        "    input_seq: array/list/torch.Tensor con ids de la oraci√≥n fuente [T_enc]\n",
        "    model: tu Seq2Seq ya cargado en 'device'\n",
        "    word2idx_outputs: dict con '<sos>' y '<eos>'\n",
        "    idx2word_target: dict id->palabra del vocab de salida\n",
        "    max_out_len: longitud m√°xima a decodificar\n",
        "    device: torch.device\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    sos = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "\n",
        "    # --- preparar encoder input [1, T_enc] como Long en device\n",
        "    if isinstance(input_seq, np.ndarray):\n",
        "        enc = torch.from_numpy(input_seq.astype(np.int64))\n",
        "    else:\n",
        "        enc = torch.as_tensor(input_seq, dtype=torch.long)\n",
        "    if enc.dim() == 1:\n",
        "        enc = enc.unsqueeze(0)  # [1, T_enc]\n",
        "    enc = enc.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # estados iniciales del decoder\n",
        "        prev_state = model.encoder(enc)                 # (h,c) con shapes [1, 1, H]\n",
        "\n",
        "        # primer token de entrada al decoder: <sos>\n",
        "        tgt = torch.tensor([[sos]], dtype=torch.long, device=device)  # [1,1]\n",
        "\n",
        "        output_words = []\n",
        "        for _ in range(max_out_len):\n",
        "            logits, prev_state = model.decoder(tgt, prev_state)   # logits: [1, 1, V]\n",
        "\n",
        "            # tomar el √∫ltimo paso temporal y argmax sobre vocab\n",
        "            next_token = logits[:, -1, :].argmax(dim=-1)          # [1]\n",
        "            idx = next_token.item()\n",
        "\n",
        "            if idx == eos:\n",
        "                break\n",
        "            # opcional: ignorar PAD(0) y <sos> si aparecen\n",
        "            if idx != 0 and idx != sos:\n",
        "                # Check if the predicted index is in the vocabulary\n",
        "                if idx in idx2word_target:\n",
        "                    output_words.append(idx2word_target[idx])\n",
        "                else:\n",
        "                    # Handle cases where the predicted index is not in the vocabulary\n",
        "                    output_words.append(f'[UNK:{idx}]') # Or some other indicator\n",
        "\n",
        "\n",
        "            # realimentar el token predicho al decoder\n",
        "            tgt = next_token.view(1, 1)                           # [1,1]\n",
        "\n",
        "    return \" \".join(output_words)"
      ],
      "metadata": {
        "id": "UMpI-I5s_EGU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducci√≥n =========\n",
        "input_test = \"My mother say hi.\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representaci√≥n en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud m√°xima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducci√≥n\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ5uslBu_r2T",
        "outputId": "bc960d28-81d1-487c-89e5-76dfc386a790"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: My mother say hi.\n",
            "Representaci√≥n en vector de tokens de ids: [18, 206, 130, 2574]\n",
            "Padding del vector: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0   18  206  130 2574]]\n",
            "Response: mi madre se cas√≥\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducci√≥n =========\n",
        "input_test = \"I like dogs and cats.\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representaci√≥n en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud m√°xima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducci√≥n\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN-rIib1ad2Y",
        "outputId": "d77d0183-d3c4-4df7-cefc-9fd9c11a821b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I like dogs and cats.\n",
            "Representaci√≥n en vector de tokens de ids: [2, 35, 575, 34, 791]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   2  35 575  34 791]]\n",
            "Response: me gusta el caf√©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducci√≥n =========\n",
        "input_test = \"I wish you happy new year.\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representaci√≥n en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud m√°xima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducci√≥n\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsPWQEsYbrVV",
        "outputId": "82aabcfb-c481-41c5-8c68-147ae4336c2e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I wish you happy new year.\n",
            "Representaci√≥n en vector de tokens de ids: [2, 311, 4, 191, 122, 232]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   2 311   4 191 122 232]]\n",
            "Response: si no te hubiera sabido nada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducci√≥n =========\n",
        "input_test = \"Today is a beautiful day.\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representaci√≥n en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud m√°xima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducci√≥n\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLpFUeXmb68n",
        "outputId": "35a3cd59-7c43-4518-d92b-4f84a8f053b9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Today is a beautiful day.\n",
            "Representaci√≥n en vector de tokens de ids: [143, 7, 6, 248, 105]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0 143   7   6 248 105]]\n",
            "Response: tom es un d√≠a soleado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= Ejemplo de traducci√≥n =========\n",
        "input_test = \"The sky is blue\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Tokenizar\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representaci√≥n en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "# Padding a la longitud m√°xima del encoder\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "# Traducci√≥n\n",
        "translation = translate_sentence(\n",
        "    encoder_sequence_test,\n",
        "    model,\n",
        "    word2idx_outputs,\n",
        "    idx2word_target,\n",
        "    max_out_len,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw5gLwBNb9ii",
        "outputId": "2a6b473f-80cd-4166-a20f-1abd79b38961"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: The sky is blue\n",
            "Representaci√≥n en vector de tokens de ids: [1, 913, 7, 804]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   1 913   7 804]]\n",
            "Response: el cielo es muy larga\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desaf√≠o 4"
      ],
      "metadata": {
        "id": "YrFtG0SHVE8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Replicar el modelo en Pytorch"
      ],
      "metadata": {
        "id": "bb3ZM3ImVejE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se replic√≥ en Pytorch el modelo provisto en Keras con los mismos par√°metros, buscando obtener los mismos resultados. Se tom√≥ como base el modelo en Keras, otro modelo provisto en clase en Pytorch, y se utiliz√≥ asistencia de un modelo de lenguaje para lograr la correspondencia entre ambos modelos.\n",
        "\n",
        "Dado que las LSTM de Keras y Pytorch no son id√©nticas, fue necesario agregar algunas funciones (glorot uniform, orthogonal per gate, set bias) para luego definir Keras_like_LSTM, y as√≠ poder replicar el modelo de Keras.\n",
        "\n",
        "Finalmente, utilizando los mismos par√°metros, se logr√≥ alcanzar una arquitectura similar:\n",
        "\n",
        "En Keras:\n",
        "\n",
        "* Total params: 1,886,336\n",
        "* Trainable params: 1,693,786\n",
        "* Non-trainable params: 192,550\n",
        "\n",
        "\n",
        "En Pytorch:\n",
        "* Total params: 1,887,410\n",
        "* Trainable params: 1,693,786\n",
        "* Non-trainable params: 193,624\n",
        "\n",
        "Al realizar el entrenamiento, se obtiene una accuracy en validaci√≥n de 0.7153, mientras que en el modelo con Keras se alcanzaba un 0.7128. Con estos resultados, se considera que los modelos son suficientemente similares para continuar con el desarrollo del trabajo."
      ],
      "metadata": {
        "id": "3ZikvuKCVcW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Pruebas con el modelo en Pytorch"
      ],
      "metadata": {
        "id": "PEfialZT9lJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realizaron distintas pruebas modificando la cantidad de datos de entrenamiento, la cantidad de palabras en el vocabulario, los tama√±os de secuencias de entrada y salida, y la cantidad de neuronas de las capas recurrentes.\n",
        "\n",
        "En cada caso, se evalu√≥ la accuracy de validaci√≥n, y se realiz√≥ la traducci√≥n de 5 frases diferentes para evaluar el desempe√±o del modelo. Se eligieron frases cortas y con palabras comunes, que idealmente deber√≠an traducirse correctamente. Las frases son:\n",
        "\n",
        "* My mother say hi (frase de prueba del modelo original en Keras)\n",
        "* I like dogs and cats\n",
        "* I wish you happy new year\n",
        "* Today is a beautiful day\n",
        "* The sky is blue\n",
        "\n",
        "Es importante destacar que los par√°metros se fueron ajustando de manera gradual, ya que al liberarlos demasiado se obtuvieron problemas relacionados a la memoria y la ejecuci√≥n fallaba. Para la realizaci√≥n de cada prueba sin problemas, fue necesario reiniciar todo el entorno de ejecuci√≥n y comenzar desde cero.\n",
        "\n",
        "En la tabla a continuaci√≥n se muestra un resumen de los par√°metros modificados y los resultados obtenidos en cada caso, sin incluir los casos que fallaron."
      ],
      "metadata": {
        "id": "hbnvCzRjXz3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| N¬∞ prueba | MAX_NUM_SENTENCES | MAX_VOCAB_SIZE | max_input_len | max_output_len | n_units | Valid acc | My mother say hi             | I like dogs and cats                                    | i wish you happy new year                    | Today is a beautiful day             | The sky is blue                     |\n",
        "|-----------|---------------------|----------------|---------------|---------------|---------|-----------|------------------------------|---------------------------------------------------------|---------------------------------------------|--------------------------------------|--------------------------------------|\n",
        "| 1         | 6000               | 8000           | 16            | 18            | 128     | 0.7153    | ella se ha ido               | -                                                       | -                                           | -                                    | -                                    |\n",
        "| 2         | 12000              | 8000           | 16            | 18            | 128     | 0.7306    | mi mam√° me gusta            | me gusta el filete medianamente cocido                  | te traje aspirina                           | tom es un chico t√≠mido              | la situaci√≥n est√° sabrosa            |\n",
        "| 3         | 36000              | 8000           | 16            | 18            | 128     | 0.7537    | mi madre se le olvid√≥ el miedo de mary | me gustan los perros                             | ojal√° hubieras guardado el nuevo            | tom es un hombre de negocios       | la situaci√≥n est√° en llamas         |\n",
        "| 4         | 36000              | 16000          | 16            | 18            | 128     | 0.7428    | mi madre tiene un minuto    | me gusta el caf√© y az√∫car                             | te quiero ayudarte                           | tom es un conductor veloz          | la verdad es que es                 |\n",
        "| 5         | 36000              | 16000          | 32            | 36            | 128     | 0.8708    | mi madre me ha ara√±ado      | me gusta el caf√©                                      | no te voy a casa ma√±ana                     | tom es un chico formal             | tom habla franc√©s                   |\n",
        "| 6         | 38000              | 16000          | 32            | 36            | 128     | 0.8725    | mi madre ha comenzado a casa| me gusta el caf√©                                      | te quiero que te guste                       | tom es un buen trabajo            | el cielo est√° despejado            |\n",
        "| 7         | 45000              | 16000          | 32            | 36            | 128     | 0.8741    | mary se le acerc√≥          | me gustan las almendras que christie que no           | quiero que t√∫ estabas aqu√≠                   | tom es un chico t√≠mido            | el cielo est√° despejado            |\n",
        "| 8         | 50000              | 18000          | 47            | 48            | 128     | 0.9057    | mary se cas√≥ con √©l        | me gusta el caf√©                                      | ayer no te habr√≠a dicho                      | tom es un buen m√©dico             | el cielo est√° despejado            |\n",
        "| 9         | 60000              | 18000          | 32            | 36            | 128     | 0.8777    | mi madre tiene que decir   | me gusta el caf√©                                      | te ayudo con ustedes                         | tom es un buen atleta            | la historia es extra√±a            |\n",
        "| 10        | 60000              | 18000          | 47            | 50            | 128     | 0.9122    | mi madre me ayud√≥         | me gusta el ingl√©s y el alem√°n                       | te har√© da√±o                                | tom es un chico astuto          | la historia es extra√±a            |\n",
        "| 11        | 60000              | 15000          | 47            | 50            | 128     | 0.9134    | mi madre se cas√≥         | me gusta el caf√©                                      | si no te hubiera sabido nada                 | tom es un d√≠a soleado          | el cielo es muy larga            |\n",
        "| 12        | 70000              | 15000          | 47            | 48            | 128     | 0.9104    | mi madre ha perdido      | me gusta el caf√©                                      | te quiero que seas feliz                     | tom es un perro grande        | el cielo est√° despejado         |\n",
        "| 13        | 60000              | 15000          | 47            | 48            | 64      | 0.9053    | mi hermano se est√° quemando | me gusta el caf√©                                   | te esperar√© aqu√≠                              | tom es un buen trabajo       | tom se est√° quedando en boston |\n",
        "| 14        | 60000              | 15000          | 47            | 48            | 256     | 0.9115    | mi madre me ense√±√≥      | me gusta el caf√© y el d√≠a                          | te deseo que no vayas                         | tom es un conductor veloz   | la situaci√≥n es desagradable  |\n",
        "| 15        | 60000              | 15000          | 47            | 48            | 512     | 0.9131    | mi madre puso su mano | me gusta el helado de chocolate                | te quiero su respeto                          | tom es un chico malo        | el cielo es azul               |\n"
      ],
      "metadata": {
        "id": "fSdLVxEgMNnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2a - Extender el entrenamiento a m√°s datos y tama√±os de secuencias mayores"
      ],
      "metadata": {
        "id": "tamIf5QXVYyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aument√≥ gradualmente la cantidad de datos de entrada, el tama√±o del vocabulario y el tama√±o de las secuencias de entrada y de salida.\n",
        "\n",
        "En todos los casos se observ√≥ que a mayor cantidad de datos y tama√±o de secuencias, mayor accuracy de validaci√≥n. Sin embargo, si se aumenta demasiado se obtienen problemas con la memoria y no se puede finalizar la ejecuci√≥n, por lo que se fue aumentando de a un par√°metro por vez.\n",
        "\n",
        "Los mayores incrementos en accuracy se observaron al modificar el tama√±o de las secuencias de entrada y salida.\n",
        "\n",
        "Es importante destacar que se evalu√≥ en conjunto la accuracy de validaci√≥n y la traducci√≥n de las 5 frases, ya que en algunos casos la mejora en accuracy no se condice con una mejora en la traducci√≥n.\n",
        "\n",
        "Esto ocurre entre las ejecuciones 4 y 5, donde se observa un incremento importante en accuracy, pero no una mejora en las traducciones. Por ejemplo, pasa de \"me gusta el caf√© y az√∫car\" a \"me gusta el caf√©\", cuando la estructura de la frase incluye dos sustantivos (\"i like dogs and cats\"). En \"i wish you happy new year\", se hab√≠a obtenido una frase que comenzaba con \"te quiero\" (m√°s similar a un \"te deseo feliz a√±o nuevo\"), y luego se obtiene una frase sin ninguna relaci√≥n con la original (\"no te voy a casa ma√±ana\").\n",
        "\n",
        "En la prueba 6, por ejemplo, se obtuvo una accuracy muy similar a la prueba anterior y a la siguiente, pero se destaca por lograr buenos resultados en la traducci√≥n: \"mi madre\", \"me gusta\", \"te quiero\" y \"el cielo est√° despejado\".\n",
        "\n",
        "En conjunto, los mejores resultados se obtuvieron en las ejecuciones 11 y 12, llevando al m√°ximo posible (sin fallas) la cantidad de sentencias utilizadas y los tama√±os de secuencias. Se obtiene una accuracy de validaci√≥n mayor a 0.91 en ambos casos, y las mejores traducciones de las frases de prueba. La ejecuci√≥n 11 se destaca ya que es la √∫nica vez que se obtiene \"es un d√≠a soleado\" para la frase 4, que suele fallar en el resto de las ejecuciones."
      ],
      "metadata": {
        "id": "W17Fn5HfEw3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2b - Explorar el impacto de la cantidad de neuronas en las capas recurrentes"
      ],
      "metadata": {
        "id": "kC2FdURlJfDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que se definieron la cantidad de sentencias, tama√±o de vocabulario y tama√±o de secuencias, se realizaron pruebas con 64, 128, 256 y 512 neuronas en las capas recurrentes, que pueden observarse en la tabla.\n",
        "\n",
        "Si bien la accuracy de validaci√≥n obtenida se relaciona directamente con la cantidad de neuronas, la diferencia en los valores es m√≠nima, y no se traduce directamente en un mejor desempe√±o en las frases de prueba.\n",
        "\n",
        "Al reducir el tama√±o a 64 se observa que empeoran los resultados con las frases de prueba (\"mi hermano\", \"tom se est√° quedando en boston\"), pero al aumentar a 256 y 512 no se observa que la mejora sea sustancial. Esto probablemente se relaciona con que al tener m√°s par√°metros entrenables se deber√≠a aumentar la cantidad de datos de entrada, y esto no es posible por los l√≠mites de memoria.\n",
        "\n",
        "Al modificar la cantidad de neuronas se observa que se modifican en la misma medida la cantidad de par√°metros del modelo.\n",
        "\n",
        "Por otro lado, a medida que se aumenta la cantidad de neuronas aumenta considerablemente el tiempo que lleva el entrenamiento. Sin embargo, se observa que la curva de accuracy de validaci√≥n alcanza un valor estable m√°s r√°pidamente, por lo que se podr√≠a reducir la cantidad de √©pocas para reducir el tiempo de entrenamiento.\n",
        "\n",
        "Observando todos los resultados en conjunto y los tiempos de entrenamiento, se decidi√≥ conservar la cantidad de neuronas iniciales de 128."
      ],
      "metadata": {
        "id": "oqKN_FwpJlOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2c - Mostrar 5 ejemplos de traducciones generadas\n",
        "\n",
        "Se muestran los resultados en la tabla y en la secci√≥n \"5 - Inferencia\"."
      ],
      "metadata": {
        "id": "AdxapOdOL2jn"
      }
    }
  ]
}